{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4d48702",
   "metadata": {},
   "source": [
    "import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1669eb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc3574f",
   "metadata": {},
   "source": [
    "read the enviroments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f362ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config() -> dict:\n",
    "    load_dotenv()\n",
    "    host = os.getenv(\"PG_HOST\")\n",
    "    user = os.getenv(\"PG_USER\")\n",
    "    password = os.getenv(\"PG_PASSWORD\")\n",
    "    db_name = os.getenv(\"PG_DB\")\n",
    "    port = os.getenv(\"PG_HOST_PORT\")\n",
    "    url = f\"jdbc:postgresql://{host}:{port}/{db_name}\"\n",
    "    res = {\n",
    "        \"host\" : host,\n",
    "        \"user\" : user,\n",
    "        \"password\" : password,\n",
    "        \"db_name\" : db_name,\n",
    "        \"port\" : port,\n",
    "        \"db_url\" : url\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7f11a4",
   "metadata": {},
   "source": [
    "Create the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e5d5e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/07 16:11:29 WARN Utils: Your hostname, MacBook-Pro.local, resolves to a loopback address: 127.0.0.1; using 10.231.32.43 instead (on interface en0)\n",
      "25/11/07 16:11:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pyspark/jars/ivy-2.5.3.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "Ivy Default Cache set to: /Users/m/.ivy2.5.2/cache\n",
      "The jars for the packages stored in: /Users/m/.ivy2.5.2/jars\n",
      "org.postgresql#postgresql added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-bf328cb5-1f16-4908-8c41-e6cf49914f71;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.postgresql#postgresql;42.7.4 in central\n",
      "\tfound org.checkerframework#checker-qual;3.42.0 in central\n",
      ":: resolution report :: resolve 91ms :: artifacts dl 3ms\n",
      "\t:: modules in use:\n",
      "\torg.checkerframework#checker-qual;3.42.0 from central in [default]\n",
      "\torg.postgresql#postgresql;42.7.4 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-bf328cb5-1f16-4908-8c41-e6cf49914f71\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/3ms)\n",
      "25/11/07 16:11:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"spark-practice\")\\\n",
    "            .config(\"spark.jars.packages\", \"org.postgresql:postgresql:42.7.4\")\\\n",
    "            .config(\"spark.sql.shuffle.partitions\", \"8\")\\\n",
    "            .getOrCreate() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb8f02",
   "metadata": {},
   "source": [
    "create the function read_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86c0a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_table(spark : SparkSession, table_name: str)-> DataFrame:\n",
    "    config = get_config()\n",
    "\n",
    "    reader = (spark.read.format(\"jdbc\")\\\n",
    "             .option(\"url\", config[\"db_url\"])\\\n",
    "             .option(\"dbtable\", table_name)\\\n",
    "             .option(\"user\", config[\"user\"])\\\n",
    "             .option(\"password\", config[\"password\"])\\\n",
    "             .option(\"driver\", \"org.postgresql.Driver\"))\n",
    "    return reader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cc4133",
   "metadata": {},
   "source": [
    "Create the dataframes of needable tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b25eae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_film = read_table(spark, \"film\")\n",
    "df_film_category = read_table(spark, \"film_category\")\n",
    "df_category = read_table(spark, \"category\")\n",
    "df_actor = read_table(spark, \"actor\")\n",
    "df_film_actor = read_table(spark, \"film_actor\")\n",
    "df_inventory = read_table(spark, \"inventory\")\n",
    "df_rental = read_table(spark, 'rental')\n",
    "df_payment = read_table(spark, 'payment')\n",
    "df_customer = read_table(spark, 'customer')\n",
    "df_address = read_table(spark, 'address')\n",
    "df_city = read_table(spark, \"city\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb4314f",
   "metadata": {},
   "source": [
    "make the query: Output the number of movies in each category, sorted in descending order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0707f60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|   category|amount|\n",
      "+-----------+------+\n",
      "|      Music|   152|\n",
      "|      Drama|   152|\n",
      "|     Travel|   151|\n",
      "|      Games|   150|\n",
      "|    Foreign|   150|\n",
      "|   Children|   150|\n",
      "|     Sci-Fi|   149|\n",
      "|     Action|   149|\n",
      "|  Animation|   148|\n",
      "|   Classics|   147|\n",
      "|     Family|   147|\n",
      "|        New|   147|\n",
      "|Documentary|   145|\n",
      "|     Sports|   145|\n",
      "|     Comedy|   143|\n",
      "|     Horror|   142|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result1 = df_category.alias(\"c\")\\\n",
    "    .join(df_film_category.alias(\"fc\"), F.col(\"c.category_id\") == F.col(\"fc.category_id\"), \"inner\")\\\n",
    "    .join(df_film.alias(\"f\"), F.col(\"f.film_id\") == F.col(\"fc.film_id\"), \"inner\")\\\n",
    "    .groupBy(\"c.name\")\\\n",
    "    .agg(F.count(\"fc.film_id\").alias(\"amount\"))\\\n",
    "    .withColumnRenamed(\"name\", \"category\")\\\n",
    "    .select(\"category\", \"amount\")\\\n",
    "    .orderBy(F.desc(\"amount\"))\n",
    "\n",
    "result1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13c3ee4",
   "metadata": {},
   "source": [
    "make the query: Output the 10 actors whose movies rented the most, sorted in descending order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdf21573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+------+\n",
      "|actor_id|        actor_name|amount|\n",
      "+--------+------------------+------+\n",
      "|     107|    DEGENERES GINA|   753|\n",
      "|     181|    CARREY MATTHEW|   678|\n",
      "|     198|       KEITEL MARY|   674|\n",
      "|     144|WITHERSPOON ANGELA|   654|\n",
      "|     102|       TORN WALTER|   640|\n",
      "|      60|       BERRY HENRY|   612|\n",
      "|     150|       NOLTE JAYNE|   611|\n",
      "|      37|        BOLGER VAL|   605|\n",
      "|      23|     KILMER SANDRA|   604|\n",
      "|      90|      GUINESS SEAN|   599|\n",
      "+--------+------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result2 = df_actor.alias(\"a\")\\\n",
    "                .join(df_film_actor.alias(\"fa\"), F.col(\"a.actor_id\") == F.col(\"fa.actor_id\"), \"inner\")\\\n",
    "                .join(df_inventory.alias(\"i\"), F.col(\"fa.film_id\") == F.col(\"i.film_id\"), \"inner\")\\\n",
    "                .join(df_rental.alias(\"r\"), F.col(\"i.inventory_id\") == F.col(\"r.inventory_id\"), \"inner\")\\\n",
    "                .groupBy('a.actor_id', F.concat_ws(' ', F.col(\"a.last_name\"), F.col(\"a.first_name\")).alias('actor_name'))\\\n",
    "                .agg(F.count(F.expr(\"*\")).alias('amount'))\\\n",
    "                .orderBy(F.desc(\"amount\"), F.col('actor_name'))\\\n",
    "                .limit(10)\n",
    "result2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f400f107",
   "metadata": {},
   "source": [
    "make the query: Output the category of movies on which the most money was spent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72c544c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------+\n",
      "|category_id|   name|   price|\n",
      "+-----------+-------+--------+\n",
      "|          9|Foreign|10507.67|\n",
      "+-----------+-------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result3 = df_category.alias(\"c\")\\\n",
    "                .join(df_film_category.alias('fc'), F.col(\"c.category_id\") == F.col(\"fc.category_id\"), \"inner\")\\\n",
    "                .join(df_inventory.alias('i'), F.col(\"fc.film_id\") == F.col(\"i.film_id\"), \"inner\")\\\n",
    "                .join(df_rental.alias('r'), F.col(\"i.inventory_id\") == F.col(\"r.inventory_id\"), \"inner\")\\\n",
    "                .join(df_payment.alias('p'), F.col(\"r.rental_id\") == F.col(\"p.rental_id\"), \"inner\")\\\n",
    "                .filter(F.col(\"p.amount\") > 0)\\\n",
    "                .groupBy('c.category_id', 'c.name')\\\n",
    "                .agg(F.sum(\"p.amount\").alias(\"price\"))\\\n",
    "                .orderBy(F.desc('price'))\\\n",
    "                .limit(1)\n",
    "result3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee67935c",
   "metadata": {},
   "source": [
    "make the query: Output the names of movies that are not in the inventory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7eadc5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------+\n",
      "|film_id|title                 |\n",
      "+-------+----------------------+\n",
      "|14     |ALICE FANTASIA        |\n",
      "|38     |ARK RIDGEMONT         |\n",
      "|148    |CHOCOLATE DUCK        |\n",
      "|171    |COMMANDMENTS EXPRESS  |\n",
      "|198    |CRYSTAL BREAKING      |\n",
      "|221    |DELIVERANCE MULHOLLAND|\n",
      "|802    |SKY MIRACLE           |\n",
      "|712    |RAIDERS ANTITRUST     |\n",
      "|742    |ROOF CHAMPION         |\n",
      "|860    |SUICIDES SILENCE      |\n",
      "|108    |BUTCH PANTHER         |\n",
      "|195    |CROWDS TELEMARK       |\n",
      "|801    |SISTER FREDDY         |\n",
      "|943    |VILLAIN DESPERATE     |\n",
      "|950    |VOLUME HOUSE          |\n",
      "|33     |APOLLO TEEN           |\n",
      "|41     |ARSENIC INDEPENDENCE  |\n",
      "|217    |DAZED PUNK            |\n",
      "|332    |FRANKENSTEIN STRANGER |\n",
      "|642    |ORDER BETRAYED        |\n",
      "|607    |MUPPET MILE           |\n",
      "|192    |CROSSING DIVORCE      |\n",
      "|404    |HATE HANDICAP         |\n",
      "|669    |PEARL DESTINY         |\n",
      "|671    |PERDITION FARGO       |\n",
      "|701    |PSYCHO SHRUNK         |\n",
      "|713    |RAINBOW SHOCK         |\n",
      "|874    |TADPOLE PARK          |\n",
      "|909    |TREASURE COMMAND      |\n",
      "|36     |ARGONAUTS TOWN        |\n",
      "|128    |CATCH AMISTAD         |\n",
      "|144    |CHINATOWN GLADIATOR   |\n",
      "|419    |HOCUS FRIDA           |\n",
      "|954    |WAKE JAWS             |\n",
      "|87     |BOONDOCK BALLROOM     |\n",
      "|318    |FIREHOUSE VIETNAM     |\n",
      "|325    |FLOATS GARDEN         |\n",
      "|359    |GLADIATOR WESTWARD    |\n",
      "|386    |GUMP DATE             |\n",
      "|495    |KENTUCKIAN GIANT      |\n",
      "|497    |KILL BROTHERHOOD      |\n",
      "|955    |WALLS ARTIST          |\n",
      "+-------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result4 = df_film.alias('f')\\\n",
    "                .join(df_inventory.alias('i'), F.col(\"f.film_id\") == F.col(\"i.film_id\"), 'left')\\\n",
    "                .filter(F.col(\"i.film_id\").isNull())\\\n",
    "                .select('f.film_id', 'f.title')\n",
    "result4.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a813046",
   "metadata": {},
   "source": [
    "make the query: Output the top 3 actors who have appeared most in movies in the “Children” category. If several actors have the same number of movies, output all of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "535ffad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/07 16:12:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:09 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/11/07 16:12:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+---------+\n",
      "|actor_id|actor_name      |films_cnt|\n",
      "+--------+----------------+---------+\n",
      "|105     |CROWE SIDNEY    |9        |\n",
      "|139     |GOODING EWAN    |9        |\n",
      "|133     |PENN RICHARD    |9        |\n",
      "|145     |ALLEN KIM       |8        |\n",
      "|181     |CARREY MATTHEW  |8        |\n",
      "|56      |HARRIS DAN      |8        |\n",
      "|131     |JACKMAN JANE    |8        |\n",
      "|87      |PECK SPENCER    |8        |\n",
      "|142     |RYDER JADA      |8        |\n",
      "|66      |TANDY MARY      |8        |\n",
      "|149     |TEMPLE RUSSELL  |8        |\n",
      "|29      |WAYNE ALEC      |8        |\n",
      "|123     |DENCH JULIANNE  |7        |\n",
      "|65      |HUDSON ANGELA   |7        |\n",
      "|108     |NOLTE WARREN    |7        |\n",
      "|34      |OLIVIER AUDREY  |7        |\n",
      "|84      |PITT JAMES      |7        |\n",
      "|94      |TORN KENNETH    |7        |\n",
      "|17      |VOIGHT HELEN    |7        |\n",
      "|95      |WAHLBERG DARYL  |7        |\n",
      "|96      |WILLIS GENE     |7        |\n",
      "|85      |ZELLWEGER MINNIE|7        |\n",
      "+--------+----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counts = df_actor.alias('a')\\\n",
    "            .join(df_film_actor.alias('fa'), F.col(\"a.actor_id\") == F.col(\"fa.actor_id\"), \"inner\")\\\n",
    "            .join(df_film_category.alias('fc'), F.col(\"fa.film_id\") == F.col(\"fc.film_id\"), \"inner\")\\\n",
    "            .join(df_category.alias(\"c\"), F.col(\"fc.category_id\") == F.col(\"c.category_id\"), 'inner')\\\n",
    "            .where(F.col(\"c.name\") == \"Children\")\\\n",
    "            .groupBy('a.actor_id', F.concat_ws(' ', \"a.last_name\", \"a.first_name\").alias(\"actor_name\"))\\\n",
    "            .agg(F.count('fa.actor_id').alias(\"films_cnt\"))\n",
    "ranked = counts.withColumn(\"rnk\", F.dense_rank().over(Window.orderBy(F.desc(\"films_cnt\"))))\n",
    "result5 = ranked.filter(F.col(\"rnk\") <= 3)\\\n",
    "          .select(\"actor_id\", \"actor_name\", \"films_cnt\")\\\n",
    "          .orderBy(F.desc(\"films_cnt\"), \"actor_name\")\n",
    "result5.show(30, truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
